{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Classification-using-pre-trained-models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYPyI0MdVTn",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch for Beginners: Comparison of pre-trained models for Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWkVRYJ_Pa-t",
        "colab_type": "code",
        "outputId": "3c6f8fe6-eec9-4215-dee8-01484485f596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Make sure torchvision-0.3.0 (latest version) is installed\n",
        "!pip install torchvision==0.3.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SlHsDqPPtMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import torch and torchvision modules\n",
        "import torch\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d7vH5B2P02M",
        "colab_type": "code",
        "outputId": "d6306d22-c0d0-4136-f22c-1ec72a67aaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        }
      },
      "source": [
        "# Print the models available in torchvision\n",
        "dir(models)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'DenseNet',\n",
              " 'GoogLeNet',\n",
              " 'Inception3',\n",
              " 'MobileNetV2',\n",
              " 'ResNet',\n",
              " 'ShuffleNetV2',\n",
              " 'SqueezeNet',\n",
              " 'VGG',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'utils',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL1bqOU_Qd-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify image transformations\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([            #[1]\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n",
        "\n",
        "# Line [1]: Here we are defining a variable transform which is a combination of all the image transformations to be carried out on the input image.\n",
        "\n",
        "# Line [2]: Resize the image to 256×256 pixels.\n",
        "\n",
        "# Line [3]: Crop the image to 224×224 pixels about the center.\n",
        "\n",
        "# Line [4]: Convert the image to PyTorch Tensor data type.\n",
        "\n",
        "# Line [5-7]: Normalize the image by setting its mean and standard deviation to the specified values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtOK2ZLTwss",
        "colab_type": "code",
        "outputId": "97457bf6-0d41-4dbf-9807-016c594fc998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Download image\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg -O dog.jpg"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-03 03:46:41--  https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83281 (81K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg’\n",
            "\n",
            "dog.jpg             100%[===================>]  81.33K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-06-03 03:46:46 (1.81 MB/s) - ‘dog.jpg’ saved [83281/83281]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G31tXCQxa1AZ",
        "colab_type": "code",
        "outputId": "edd82d25-72ed-4c0a-afb2-d48e610adeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Download classes text file\n",
        "!wget https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-03 03:46:49--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2019-06-03 03:46:49 (2.89 MB/s) - ‘imagenet_classes.txt’ saved [21674/21674]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jex0-5RuaNRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"dog.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbPGrVeRapB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_t = transform(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HoQbsp8coVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d41d63e4-b47c-49e3-9aee-92b084093561"
      },
      "source": [
        "# Load alexnet model\n",
        "alexnet = models.alexnet(pretrained=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n",
            "100%|██████████| 244418560/244418560 [00:05<00:00, 45622470.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FetOTbiTc72w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "e5bfa8bf-a555-42e0-fbf0-0d82cfcfcf02"
      },
      "source": [
        "print(alexnet)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Dropout(p=0.5)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBc7fC2Hc-Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "79aa6483-dd26-455f-db37-0c44cc34b6e3"
      },
      "source": [
        "# Put our model in eval mode\n",
        "alexnet.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtZvoeNkdCkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "582ef133-c73a-4702-faa4-b5c144085713"
      },
      "source": [
        "# Carry out inference\n",
        "out = alexnet(batch_t)\n",
        "print(out.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5pqY-qXdDgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load labels\n",
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OATsity0dGoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1e9cf967-f8d7-4468-ddb8-778042e1b7be"
      },
      "source": [
        "_, indices = torch.sort(out, descending=True)\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "[(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Labrador retriever', 41.585166931152344),\n",
              " ('golden retriever', 16.59166145324707),\n",
              " ('Saluki, gazelle hound', 16.286880493164062),\n",
              " ('whippet', 2.8539133071899414),\n",
              " ('Ibizan hound, Ibizan Podenco', 2.3924720287323)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}